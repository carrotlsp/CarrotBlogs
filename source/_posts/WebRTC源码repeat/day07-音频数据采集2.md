---
title: day07-音频数据采集2-ADM创建过程、本地音频的采集&&加密封装&&传输
date: 2022-11-25 07:35:29
tags: 
	- WebRTC
categories: 
	- WebRTC源码Repeat

---

### 1、ADM在iOS上创建过程？

```c++
- (instancetype)
    initWithEncoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoEncoderFactory)>)encoderFactory
            decoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoDecoderFactory)>)decoderFactory 
{
	调用 [self audioDeviceModule].get() 获取ADM
}

- (rtc::scoped_refptr<webrtc::AudioDeviceModule>)audioDeviceModule
{
	调用 webrtc::CreateAudioDeviceModule() 继续创建ADM
	再间距调用 rtc::scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(bool bypass_voice_processing) 继续创建
}

rtc::scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(bool bypass_voice_processing) 
{
	调用 rtc::make_ref_counted<ios_adm::AudioDeviceModuleIOS>(bypass_voice_processing) 最终创建了出了ADM是AudioDeviceModuleIOS类型
}
```



### 2、音频类持有关系？

```c++
PeerConnectionFactory -> 持有 👇🏻

PeerConnectionFactoryDependencies（dependencies）-> 持有 👇🏻

CompositeMediaEngine （media_engine）-> 持有 👇🏻

WebRtcVoiceEngine（audio_engine）-> 持有 👇🏻

MediaEngineDependencies -> 持有 👇🏻

AudioDeviceModule（adm）-> 持有 👇🏻 -> 还持有 AudioDeviceBuffer

AudioDeviceIOS（audio_device_）-> 持有 👇🏻  -> 还持有 AudioDeviceBuffer

VoiceProcessingAudioUnit（audio_unit_）
这个类才是真正用于音频的录制与播放的
```



### 3、kInputBus ==1和 kInputBus ==0分别代表什么？

```c++
关键知识点 👇🏻 
// A VP I/O unit's bus 1 connects to input hardware (microphone).
static const AudioUnitElement kInputBus = 1;
// A VP I/O unit's bus 0 connects to output hardware (speaker).
static const AudioUnitElement kOutputBus = 0;
```



### 4、本地音频流转线路（保存）<font color="red">【important】</font>？

```c
AudioDeviceIOS::OnDeliverRecordedData （从上面的audio_unit_回调的数据）
{
	调用 audio_unit_->Render() 函数，对音频数据进行获取
	调用 fine_audio_buffer_->DeliverRecordedData() 函数，对音频数据转换成Webrtc的buffer。
}


void FineAudioBuffer::DeliverRecordedData  
{
	将音频10毫秒进行分割
	将处理好的音频放入 audio_device_buffer_->SetVQEData 中
	然后调用 AudioDeviceBuffer::DeliverRecordedData 进行下一步的处理
}

int32_t AudioDeviceBuffer::DeliverRecordedData
{
	调用 audio_transport_cb_->RecordedDataIsAvailable 继续处理数据
}


int32_t AudioTransportImpl::RecordedDataIsAvailable
{
	对音频数据封装成 AudioFrame
	对音频数据重采样和混音 voe::RemixAndResample
	对音频使用应用层算法 ProcessCaptureFrame
	调用 SendProcessedData 将 AudioFrame 发出去
}


void AudioTransportImpl::SendProcessedData 
{
	遍历所有的音频发送器（audio_senders_、AudioSender）
	每个音频发送器发送一遍 AudioFrame
	最后，原始的 audio_frame 被发送给第一个音频发送器，避免额外的数据复制。
}

void AudioSendStream::SendAudioData
{
	调用 channel_send_->ProcessAndEncodeAudio 将数据进行发送
}


void ChannelSend::ProcessAndEncodeAudio
{
	将音频放入 encoder_queue_ (rtc::TaskQueue) 队列等待处理
	队列执行时，调用audio_coding_（AudioCodingModule::Add10MsData）
}

int AudioCodingModuleImpl::Add10MsData 
{
	Add10MsDataInternal 对音频的采样率、声道数、长度做出判断，如果数据不合规，就抛弃掉
	Add10MsDataInternal 调用 AudioCodingModuleImpl::PreprocessToAddData 对音频进行检查，如果采样率、声道数、混音不符合要求，会进行重采样
	最后调用 Encode 对音频进行处理，这段代码是音频编码的核心部分，将音频数据传递给编码器进行压缩，并将编码后的数据发送给后续的数据传输流程
}


int32_t AudioCodingModuleImpl::Encode
{
	通过 音频数据 换算出 RTP包的时间戳，rtp_timestamp
	调用 AudioEncoder::EncodedInfo AudioEncoder::Encode 进行编码处理
	{
		AudioEncoder::EncodedInfo AudioEncoderOpusImpl::EncodeImpl //TODO
	}
	发送给回调函数 packetization_callback_->SendData ，进行下一步处理
}


int32_t ChannelSend::SendData
{
	调用 SendRtpAudio() 发送音频数据
}


int32_t ChannelSend::SendRtpAudio
{
	在RTP扩展头中设置audioLevel
	如果有加密器，就对音频进行加密（默认情况下WebRTC没进行加密）
	调用 ModuleRtpRtcpImpl2::OnSendingRtpFrame 判断是否可以发送音频以及RTCP收集一些信息
	再调用 RTPSenderAudio::SendAudio 把数据发送到RTP音频发送器模块
}

bool RTPSenderAudio::SendAudio
{
	判断是否开启DTMF，进行一些列特殊处理（WebRTC默认不走此逻辑）
	构建出 RtpPacketToSend 对象，并且对packet配置所有需要的数据，比如PayloadType、TimeStamp、payloadData…
	调用 RTPSender::SendToNetwork 将数据继续投递
}


bool RTPSender::SendToNetwork
{
	会调用 paced_sender_->EnqueuePackets(std::move(packets)) 将音频数据压入队列中
	RTP发送器会根据网络带宽和拥塞情况进行发送速率的控制，以平滑的发送数据
}


class RtpPacketSenderProxy
void EnqueuePackets
{
	调用 rtp_packet_pacer_->EnqueuePackets 将数据压入队列中
}


void TaskQueuePacedSender::EnqueuePackets
{
	创建一个Block，将Block放入 rtc::TaskQueue task_queue_ 队列中，待执行。
	//TODO 这个task_queue_ 什么时候会被执行呢？是否进行了速率控制？
	Block执行时，调用 pacing_controller_.EnqueuePacket(std::move(packet)); 进行将任务压入队列
}

void PacingController::EnqueuePacket
{
	调用 BitrateProber::OnIncomingPacket 使用包的有效负载大小通知拥塞控制器，以便进行拥塞控制。
	调用 PrioritizedPacketQueue::Push 将数据包压入队列中
}

void PrioritizedPacketQueue::Push
{
	根据优先级进行排序
	同时还包括了对队列大小、停留时间和定期清理的统计和管理。
	然后把 RtpPacketToSend 转换成 QueuedPacket，并且携带一些控制配置
	最后调用 stream_queue->EnqueuePacket 将 QueuedPacket 插入到队列中
}
```



### 5、本地音频流转线路（发送）<font color="red">【important】</font>？

// TODO 还需要看下RTP和DTLS是如何对它们进行处理的？

```c
void PacingController::ProcessPackets
{
	调用 GetPendingPacket 获取 RtpPacketToSend 对象，最终调用 std::unique_ptr<RtpPacketToSend> PrioritizedPacketQueue::Pop 获取
	调用 void PacketRouter::SendPacket 将
}

void PacketRouter::SendPacket
{
	设置音频数据包的sequenceNumber
	通过音频数据包的 ssrc 获取 rtp_module
	通过rtp_module 的 ModuleRtpRtcpImpl2::TrySendPacket  尝试发送数据包
	最后如果开启FEC，还要把数据给到FEC模块
}

bool ModuleRtpRtcpImpl2::TrySendPacket
{
	进行一些参数判断
	调用 RtpSenderEgress::SendPacket 进行数据发送
}


void RtpSenderEgress::SendPacket 
{
	对packet的extension进行一些设置
	调用 AddPacketToTransportFeedback 将包的一些数据给到feedback模块
	调用 SendPacketToNetwork 进行包的发布
	如果发布成功，做一些标记
}

bool RtpSenderEgress::SendPacketToNetwork
{
	调用 WebRtcVoiceMediaChannel::SendRtp 的方法进行发送
}

void MediaChannel::SendRtp
{
	封装一个Block，将Block扔到 network_thread_->PostTask 队列中调用
	
	调用 MediaChannel::SendPacket 继续发送
}

bool MediaChannel::SendPacket 
{
	调用 BaseChannel::SendPacket 继续发送数据
}


bool BaseChannel::SendPacket 
{
	调用 bool SrtpTransport::SendRtpPacket 继续发送
}

bool SrtpTransport::SendRtpPacket  
{
	调用 bool RtpTransport::SendPacket 继续发送
}

bool RtpTransport::SendPacket
{
	调用 int DtlsTransport::SendPacket 继续发送
}


int DtlsTransport::SendPacket
{
	首先会保证 DTLS处于 webrtc::DtlsTransportState::kConnected 状态
	然后调用 ice_transport_->SendPacket 继续发送
}

int P2PTransportChannel::SendPacket
{
	调用 selected_connection_->Send 继续发送数据
}

int ProxyConnection::Send
{
	调用 int TurnPort::SendTo 继续数据发送
}

int TurnPort::SendTo
{
	调用 int TurnEntry::Send 继续发送
}

int TurnEntry::Send
{
	将音频包构建成 ByteBufferWriter 和 TurnMessage 结构
	调用 int TurnPort::Send 继续发送
}

int TurnPort::Send
{
	调用 socket_->SendTo 继续发送
}

int AsyncUDPSocket::SendTo
{
	将数据构建成 rtc::SentPacket 数据结构
	调用 socket_->SendTo 继续发送
}

int PhysicalSocket::SendTo
{
	调用 DoSendTo 继续发送
}

int PhysicalSocket::DoSendTo
{
	调用 ::sendto(socket, buf, len, flags, dest_addr, addrlen) 继续发送，这次真的发送出去了，太长了吧。
}

```





### 6、不让WebRTC的SDK在Debug模式下，自动输出日志要怎么做？

```c
// logging.cc 文件下修改

#if !defined(NDEBUG)
constexpr LoggingSeverity kDefaultLoggingSeverity = LS_NONE;
#else
constexpr LoggingSeverity kDefaultLoggingSeverity = LS_NONE;
#endif
```



### 
