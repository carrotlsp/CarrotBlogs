---
title: day07-音频数据采集3-将WebRtc接受的原始PCM和压缩数据保存到本地进行分析
date: 2022-11-25 09:36:29
tags: 
	- WebRTC
categories: 
	- WebRTC源码Repeat

---





## 一、 内部功能，音频相关

#### 1、`rtp_send_cache` 是 app 本地音频压缩文件

- app 端的在 RTP 即将发送出去的的时候，调用 `lds_local_record` 函数进行音频数据的保存。
- 是 c 函数，因为 app 只会投递音频，不会投递视频，所以记录的地方比较暴力，在 `RtpSenderEgress::SendPacketToNetwork` 方法中直接写文件了。
- 在 `Audacity` 中 `文件 -> 导入 -> 原始数据` 选择 编码:`A-Law`、字节序:`默认尾端(endianness)`、声道数:`单声道`、采样率:`8000Hz`

#### 2、`capture_pcm_cache` 是 app 本地捕获的原始音频的 PCM 文件

- 调用 `lds_pcm_capture_record` 进行文件写入
- 在 `AudioDeviceIOS::OnDeliverRecordedData` 进行音频数据的写入
- 在 `Audacity` 中 `文件 -> 导入 -> 原始数据` 选择 编码:`Signed 16-bit PCM`、字节序:`默认尾端(endianness)`、声道数:`单声道`、采样率:`48000Hz`

#### 3、`rtp_recv_cache` 是设备远端音频压缩文件

- 调用 `lds_rtp_recv_record` 进行文件写入
- 在 `NetEqImpl::InsertPacketInternal` 在 NetEq 模块进行写入，记录 RTP 数据
- 在 `Audacity` 中 `文件 -> 导入 -> 原始数据` 选择 编码:`A-Law`、字节序:`默认尾端(endianness)`、声道数:`单声道`、采样率:`8000Hz`

#### 4、`render_pcm_cache` 是设备远端音频解压的 PCM 文件

- 调用 `lds_pcm_record` 进行文件写入
- 在 `AudioDeviceIOS::OnGetPlayoutData` 文件中获取相关的数据
- 在 `Audacity` 中 `文件 -> 导入 -> 原始数据` 选择 编码:`Signed 16-bit PCM`、字节序:`默认尾端(endianness)`、声道数:`单声道`、采样率:`48000Hz`

## 二、降噪思路

- 对于发送的音频，WebRtc有开启默认降噪模式，也就是三A算法中的降噪算法，在iOS上调用的是苹果自带的降噪算法。
- 对于接收的音频，WebRtc没有降噪算法，可以考虑在接收端加一个NSx的降噪算法。
- 因为有降噪算法，所以有时候就需要分析收到的原始音频数据和最终播放的音频数据之间的差异。分析这两者的差异就需要将这两者数据进行收集，然后使用Audacity进行分析。

## 三、Audacity 使用方法

- 打开音频片段之后，旋转 `对数(dB)`的波形图之后，如果噪音范围在`-40分贝`以下，就是噪音较小。
- 如果底噪到达 `-20分贝`，就底噪比较大了。

## 四、C 语言文件写入日志的代码结构

```
void lds_start_pcm_capture_record(char *file_name) {
    pthread_mutex_lock(&g_pcm_capture_mutex);
    if (g_pcm_capture_audio_file) {
        fclose(g_pcm_capture_audio_file);
        g_pcm_capture_audio_file = NULL;
    }
    g_pcm_capture_audio_file = fopen(file_name, "a");
    pthread_mutex_unlock(&g_pcm_capture_mutex);
}

void lds_pcm_capture_record(uint8_t *data,size_t size) {
    if (!g_pcm_capture_audio_file) {
        return;
    }
    pthread_mutex_lock(&g_pcm_capture_mutex);
    if (g_pcm_capture_audio_file) {
        fwrite(data,sizeof(uint8_t),size,g_pcm_capture_audio_file);
    }
    pthread_mutex_unlock(&g_pcm_capture_mutex);
}

void lds_stop_capture_pcm_record() {
    pthread_mutex_lock(&g_pcm_capture_mutex);
    if (g_pcm_capture_audio_file) {
        fclose(g_pcm_capture_audio_file);
        g_pcm_capture_audio_file = NULL;
    }
    pthread_mutex_unlock(&g_pcm_capture_mutex);
}
```

## 五、4 个核心获取数据的地方

- `lds_local_record` 获取 app 本地音频压缩文件

```
bool RtpSenderEgress::SendPacketToNetwork(const RtpPacketToSend& packet,
                                          const PacketOptions& options,
                                          const PacedPacketInfo& pacing_info) {
  int bytes_sent = -1;
  if (transport_) {
    bytes_sent = transport_->SendRtp(packet.data(), packet.size(), options)
                     ? static_cast<int>(packet.size())
                     : -1;
    if (event_log_ && bytes_sent > 0) {
      event_log_->Log(std::make_unique<RtcEventRtpPacketOutgoing>(
          packet, pacing_info.probe_cluster_id));
    }
      lds_local_record((uint8_t *)packet.PayloadBuffer().cdata(), (size_t)packet.payload_size());
  }
    RTC_LOG(LS_INFO) << "SendPacketToNetwork " << packet.ToString();

  if (bytes_sent <= 0) {
    RTC_LOG(LS_WARNING) << "Transport failed to send packet.";
    return false;
  }
  return true;
}
```

- `lds_pcm_capture_record` 获取 app 本地捕获的原始音频的 PCM 文件

```
OSStatus AudioDeviceIOS::OnDeliverRecordedData(AudioUnitRenderActionFlags* flags,
                                               const AudioTimeStamp* time_stamp,
                                               UInt32 bus_number,
                                               UInt32 num_frames,
                                               AudioBufferList* /* io_data */) {
  RTC_DCHECK_RUN_ON(&io_thread_checker_);
  OSStatus result = noErr;
  if (!rtc::AtomicOps::AcquireLoad(&recording_)) return result;
  AudioBufferList audio_buffer_list;
  audio_buffer_list.mNumberBuffers = 1;
  AudioBuffer* audio_buffer = &audio_buffer_list.mBuffers[0];
  audio_buffer->mNumberChannels = record_parameters_.channels();
  audio_buffer->mDataByteSize =
      record_audio_buffer_.size() * VoiceProcessingAudioUnit::kBytesPerSample;
  audio_buffer->mData = reinterpret_cast<int8_t*>(record_audio_buffer_.data());
  result = audio_unit_->Render(flags, time_stamp, bus_number, num_frames, &audio_buffer_list);
  if (result != noErr) {
    RTCLogError(@"Failed to render audio.");
    return result;
  }
    if (inputGainFactor_ != 1) {
        short *audio_byte = static_cast<short *>(audio_buffer->mData);
        uint32_t audio_size = audio_buffer->mDataByteSize/2;
        for(UInt32 i = 0; i < audio_size; i++) {
            audio_byte[i] *= inputGainFactor_;
        }
    }
    uint8_t *data;
    if (lds_get_capture_data(&data,(size_t)audio_buffer->mDataByteSize) > 0) {
        memcpy(audio_buffer->mData, data, (size_t)audio_buffer->mDataByteSize);
    }
    lds_pcm_capture_record((uint8_t *)audio_buffer->mData,(size_t)audio_buffer->mDataByteSize);


  // Get a pointer to the recorded audio and send it to the WebRTC ADB.
  // Use the FineAudioBuffer instance to convert between native buffer size
  // and the 10ms buffer size used by WebRTC.
  fine_audio_buffer_->DeliverRecordedData(record_audio_buffer_, kFixedRecordDelayEstimate);
  return noErr;
}
```

- `lds_rtp_recv_record` 是设备远端音频压缩文件

```
int NetEqImpl::InsertPacketInternal(const RTPHeader& rtp_header,
                                    rtc::ArrayView<const uint8_t> payload) {
  if (payload.empty()) {
    RTC_LOG_F(LS_ERROR) << "payload is empty";
    return kInvalidPointer;
  }

  RTC_LOG(LS_VERBOSE) << "InsertPacket pt="<<rtp_header.payloadType<<" payload_size="<<payload.size() << " seq=" << rtp_header.sequenceNumber << " timestamp=" << rtp_header.timestamp << " BufferSize:"<<packet_buffer_->NumPacketsInBuffer();
    lds_rtp_recv_record((uint8_t *)payload.data(), payload.size());
  Timestamp receive_time = clock_->CurrentTime();
  stats_->ReceivedPacket();

  PacketList packet_list;
  // Insert packet in a packet list.
  packet_list.push_back([&rtp_header, &payload, &receive_time] {
    // Convert to Packet.
    Packet packet;
    packet.payload_type = rtp_header.payloadType;
    packet.sequence_number = rtp_header.sequenceNumber;
    packet.timestamp = rtp_header.timestamp;
    packet.payload.SetData(payload.data(), payload.size());
    packet.packet_info = RtpPacketInfo(rtp_header, receive_time);
    // Waiting time will be set upon inserting the packet in the buffer.
    RTC_DCHECK(!packet.waiting_time);
    return packet;
  }());
}
```

- `lds_pcm_record` 获取设备远端音频解压的 PCM 文件

```
OSStatus AudioDeviceIOS::OnGetPlayoutData(AudioUnitRenderActionFlags* flags,
                                          const AudioTimeStamp* time_stamp,
                                          UInt32 bus_number,
                                          UInt32 num_frames,
                                          AudioBufferList* io_data) {
  RTC_DCHECK_RUN_ON(&io_thread_checker_);
  // Verify 16-bit, noninterleaved mono PCM signal format.
  RTC_DCHECK_EQ(1, io_data->mNumberBuffers);
  AudioBuffer* audio_buffer = &io_data->mBuffers[0];
  RTC_DCHECK_EQ(1, audio_buffer->mNumberChannels);

  if (!rtc::AtomicOps::AcquireLoad(&playing_)) {
    const size_t size_in_bytes = audio_buffer->mDataByteSize;
    RTC_CHECK_EQ(size_in_bytes / VoiceProcessingAudioUnit::kBytesPerSample, num_frames);
    *flags |= kAudioUnitRenderAction_OutputIsSilence;
    memset(static_cast<int8_t*>(audio_buffer->mData), 0, size_in_bytes);
    return noErr;
  }

  ++num_playout_callbacks_;
  const int64_t now_time = rtc::TimeMillis();
  if (time_stamp->mSampleTime != num_frames) {
    const int64_t delta_time = now_time - last_playout_time_;
    const int glitch_threshold = 1.6 * playout_parameters_.GetBufferSizeInMilliseconds();
    if (delta_time > glitch_threshold) {
      RTCLogWarning(@"Possible playout audio glitch detected.\n"
                     "  Time since last OnGetPlayoutData was %lld ms.\n",
                    delta_time);
      if (glitch_threshold < 120 && delta_time > 120) {
        RTCLog(@"Glitch warning is ignored. Probably caused by device switch.");
      } else {
        thread_->Post(RTC_FROM_HERE, this, kMessageTypePlayoutGlitchDetected);
      }
    }
  }
  last_playout_time_ = now_time;

    int64_t timestamp;
  fine_audio_buffer_->GetPlayoutData(
      rtc::ArrayView<int16_t>(static_cast<int16_t*>(audio_buffer->mData), num_frames),
      kFixedPlayoutDelayEstimate,&timestamp);

//    lds_save_remote_au_data((uint8_t *)audio_buffer->mData,(size_t)audio_buffer->mDataByteSize);
    lds_pcm_record((uint8_t *)audio_buffer->mData,(size_t)audio_buffer->mDataByteSize);

  if (audio_device_buffer_->audio_transport_cb_2) {
      if (timestamp <= 0) {
          return noErr;
      }
      RTC_LOG(LS_INFO) << "[webrtc] fine_audio_buffer_->GetPlayoutData " << audio_buffer->mDataByteSize << " last_playout_time_: " << last_playout_time_ << "sampleRate:"<<playout_parameters_.sample_rate() << "channels: "<<playout_parameters_.channels();
      size_t num_samples_out(0);

      int res = audio_device_buffer_->audio_transport_cb_2->NeedMorePlayData(
          audio_buffer->mDataByteSize, io_data->mNumberBuffers, audio_buffer->mNumberChannels,
          playout_parameters_.sample_rate(), audio_buffer->mData, num_samples_out,
          &last_playout_time_, &last_playout_time_);
      res = 0;
  }
    if (play_callback_) {
//        uint8_t *, size_t, size_t, size_t, uint32_t, size_t, int64_t
        play_callback_((uint8_t *)audio_buffer->mData,(size_t)audio_buffer->mDataByteSize,(size_t)audio_buffer->mNumberChannels,(size_t)playout_parameters_.sample_rate(),1024,0,(int64_t)last_playout_time_);
    }
    if (speaker_mute_) {
        //若是扬声器经营,则把数据清零,让扬声器空转
        memset(audio_buffer->mData, 0, audio_buffer->mDataByteSize);
    }
  return noErr;
}
```
